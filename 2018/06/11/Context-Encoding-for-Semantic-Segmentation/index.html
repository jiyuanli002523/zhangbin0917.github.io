<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.4.1" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.4.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.4.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.4.1">


  <link rel="mask-icon" href="/images/logo.svg?v=6.4.1" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.4.1',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="提出了Context Encoding Module来捕获场景的语义上下文并选择性地强调与类别相关的特征图，所提出的EncNet实现了新的state-of-the-art的结果。在PASCAL-Context达到51.7% mIoU, 在PASCAL VOC 2012达到85.9% mIoU，单个模型在ADE20K test set达到0.5567,超过了COCO-Place Challenge">
<meta name="keywords" content="Semantic Segmentation,Channel Attention mechanism">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读 - Context Encoding for Semantic Segmentation&lt;br&gt;(CVPR2018)">
<meta property="og:url" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/index.html">
<meta property="og:site_name" content="Zhang Bin&#39;s Blog">
<meta property="og:description" content="提出了Context Encoding Module来捕获场景的语义上下文并选择性地强调与类别相关的特征图，所提出的EncNet实现了新的state-of-the-art的结果。在PASCAL-Context达到51.7% mIoU, 在PASCAL VOC 2012达到85.9% mIoU，单个模型在ADE20K test set达到0.5567,超过了COCO-Place Challenge">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/01.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/00.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/01.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/02.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/03.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/04.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/05.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/06.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/07.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/08.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/09.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/10.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/11.png">
<meta property="og:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/12.png">
<meta property="og:updated_time" content="2018-06-20T08:24:05.966Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="论文阅读 - Context Encoding for Semantic Segmentation&lt;br&gt;(CVPR2018)">
<meta name="twitter:description" content="提出了Context Encoding Module来捕获场景的语义上下文并选择性地强调与类别相关的特征图，所提出的EncNet实现了新的state-of-the-art的结果。在PASCAL-Context达到51.7% mIoU, 在PASCAL VOC 2012达到85.9% mIoU，单个模型在ADE20K test set达到0.5567,超过了COCO-Place Challenge">
<meta name="twitter:image" content="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/01.png">






  <link rel="canonical" href="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>论文阅读 - Context Encoding for Semantic Segmentation<br>(CVPR2018) | Zhang Bin's Blog</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Zhang Bin's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">Less interests, more interest!!!</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />Tags</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />Categories</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />Archives</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />About</a>
  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/11/Context-Encoding-for-Semantic-Segmentation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Bin Zhang">
      <meta itemprop="description" content="I am currently a Master candidate in Wuhan University majoring Photogrammetry and remote sensing">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhang Bin's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">论文阅读 - Context Encoding for Semantic Segmentation<br>(CVPR2018)
              
            
          </h1>
        

        <div class="post-meta">
		
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-06-11 13:00:53" itemprop="dateCreated datePublished" datetime="2018-06-11T13:00:53+08:00">2018-06-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-06-20 16:24:05" itemprop="dateModified" datetime="2018-06-20T16:24:05+08:00">2018-06-20</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Semantic-Segmentation/" itemprop="url" rel="index"><span itemprop="name">Semantic Segmentation</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Symbols count in article: </span>
                
                <span title="Symbols count in article">8.1k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">7 mins.</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>提出了Context Encoding Module来捕获场景的语义上下文并选择性地强调与类别相关的特征图，所提出的EncNet实现了新的state-of-the-art的结果。在PASCAL-Context达到51.7% mIoU, 在PASCAL VOC 2012达到85.9% mIoU，单个模型在ADE20K test set达到0.5567,超过了COCO-Place Challenge 2017的冠军。Context Encoding Module也可以改善用于分类的相对较浅的网络的特征表达，在CIFAR-10上14层的网络实现了3.45%的错误率与state-of-the-art approaches的10倍多层网络的精度相当。<br><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/01.png" alt=""><br><a id="more"></a></p>
<p>paper: <a href="https://arxiv.org/abs/1803.08904" target="_blank" rel="noopener">https://arxiv.org/abs/1803.08904</a><br><a href="http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Context_Encoding_for_CVPR_2018_paper.html" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_Context_Encoding_for_CVPR_2018_paper.html</a><br>code: <a href="https://github.com/zhanghang1989/PyTorch-Encoding" target="_blank" rel="noopener">https://github.com/zhanghang1989/PyTorch-Encoding</a><br>author：<a href="http://hangzh.com/" target="_blank" rel="noopener">Hang Zhang</a>, <a href="http://eceweb1.rutgers.edu/vision/dana.html" target="_blank" rel="noopener">Kristin Dana</a>, <a href="http://shijianping.me/" target="_blank" rel="noopener">Jianping Shi</a>, <a href="http://zhongyuezhang.com/" target="_blank" rel="noopener">Zhongyue Zhang</a>, <a href="http://www.ee.cuhk.edu.hk/~xgwang/" target="_blank" rel="noopener">Xiaogang Wang</a>, <a href="https://scholar.google.com/citations?user=GaSWCoUAAAAJ&amp;hl=en" target="_blank" rel="noopener">Ambrish Tyagi</a>, <a href="http://www.amitkagrawal.com/" target="_blank" rel="noopener">Amit Agrawal</a></p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h1><p>最近语义分割网络使用基于多分辨率金字塔来扩大感受野，如PSPSNet中的Spatial Pyramid Pooling和Deeplab中的Atrous Spatial Pyramid Pooling。虽然这些方法可以提升性能，但是上下文地表达不明确，导致了一个问题：增加感受野就等同于整合了上下文信息了吗？如图所示是来自于ADE20K中的一张图片，包含150个类别。如果允许标注者先选择图像的语境(如卧室)，接着工具会提供一个小的相关的类别列表(如床，椅子等)，这会极大地减少可能的类别搜索空间。同样，如果可以设计一个方法来充分利用场景语境类别的概率的关系，对网络来说语义分割会更容易。<br><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/00.png" alt=""><br>是否可以把传统方法的上下文编码和深度学习结合？之前作者就设计了一个Encoding Layer整合字典学习和残差编码过程到一个CNN层中来捕获无序的表达，在纹理分类中获得了state-of-the-art的结果。在这篇论文中作者延申Encoding Layer来捕获全局特征统计信息来理解语义上下文。<br>这篇论文的两个贡献：</p>
<ol>
<li>提出了Context Encoding Module。在Context Encoding Module中还包含Semantic Encoding Loss(SE-Loss)，一个利用全局场景上下文信息的单元。Context Encoding Module可以捕获场景的语义上下文并选择性地强调与类别相关的特征图。常规的训练过程中只用了逐像素的分割loss，没有利用场景的上下文。引入Semantic Encoding Loss(SE-Loss)来正则化训练，让网络预测在场景中物体种类的出现概率来强制网络学习语义上下文。而且SE-Loss同等对待大物体和小物体，发现小物体的实际分割效果有提升。</li>
<li>设计了一个语义分割网络Context Encoding Network (EncNet)。EncNet在预训练的ResNet中通过引入了Context Encoding Module强化网络。使用了dilation convolution。</li>
</ol>
<h1 id="2-Context-Encoding-Module"><a href="#2-Context-Encoding-Module" class="headerlink" title="2. Context Encoding Module"></a>2. Context Encoding Module</h1><p><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/01.png" alt=""></p>
<h2 id="Context-Encoding"><a href="#Context-Encoding" class="headerlink" title="Context Encoding"></a>Context Encoding</h2><p>Encoding Layer输入为$H×W×C$的特征图，之后reshape为$N(H×W)$个$C$维的vector $X=\lbrace{x_1,…,x_N}\rbrace$，在Encoding Layer中要学习codebook $D=\lbrace{d_1,…,d_K}\rbrace$其中包含K个codeword以及smoothing factor $S=\lbrace{s_1,…,s_K}\rbrace$。<br>Encoding Layer输出为k个残差编码$e_k$，每个残差编码的维度为$C$，残差编码$e_k$是对soft-assignment weights的残差求和得到的: $e_k=\sum_{i=1}^N{e_{ik}}$。<br>残差计算方法：$r_{ik}=x_i-d_k$<br>soft-assignment weights残差计算方法：$e_{ik}=\frac{exp(-s_k{\left|r_{ik}\right|}^2)}{\sum_{j=1}^K{exp(-s_j{\left|r_{ij}\right|}^2)}}r_{ik}$。<br>最终对编码求和而不是concatenate，即$e=\sum_{k=1}^K{\phi{(e_k)}}$，其中$\phi$为BN和ReLU，这样避免了K个编码有序同时也减少了特征表达的维度。</p>
<h2 id="Featuremap-Attention"><a href="#Featuremap-Attention" class="headerlink" title="Featuremap Attention"></a>Featuremap Attention</h2><p>为了利用编码层捕获的编码的语义信息，预测了特征图的权重因子最为反馈来强调或不强调与类别相关的特征图。这里使用了全连接层和sigmoid激活函数使得输出为0到1之间。然后与特征图作逐通道相乘，与SENet类似。</p>
<h2 id="Semantic-Encoding-Loss"><a href="#Semantic-Encoding-Loss" class="headerlink" title="Semantic Encoding Loss"></a>Semantic Encoding Loss</h2><p>由于标准的训练过程中网络从孤立的像素计算loss，，因此网络没有全局信息很难理解上下文，为了正则化Context Encoding Module的训练过程，引入了Semantic Encoding Loss(SE-loss)，SE-loss以非常小的计算代价强制网络理解全局信息。在Encoding Layer上额外加入一个全连接层和sigmoid激活函数用binary cross entropy loss来预测在场景中是否有某一类存在。在实际中，发现对于小物体的分割有改进。</p>
<h2 id="2-1-Context-Encoding-Network-EncNet"><a href="#2-1-Context-Encoding-Network-EncNet" class="headerlink" title="2.1 Context Encoding Network (EncNet)"></a>2.1 Context Encoding Network (EncNet)</h2><p><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/02.png" alt=""><br>在Context Encoding Module基础上用预训练的ResNet构造了Context Encoding Network (EncNet)。在EncNet的stage3和stage4中也采用了dilated network strategy使输出为原图大小的1/8，之后上采样8倍还原。在ResNet最后加入Context Encoding Module和SE-loss。因为Context Encoding Module和SE-loss是轻量级的，所以在stage3后也加入了Context Encoding Module和SE-loss。</p>
<p>例如特征图大小为$32×32×512$，reshape后得到1024(32*32)个512维的向量，在Encoding Layer中有k=32个512维的向量$d_k$，残差编码$e_1$是1024个向量与32个向量中的第一个向量差的和，其他残差编码同理。这样得到32个残差编码，之后通过BN和ReLU在求和得到512维的向量再通过fc层和sigmoid激活函数得到每个通道的权重。作者这里用了residual，将加权后的特征图与原特征图求和后通过conv6使通道数与类别数一致最后再上采样与原始图像大小一致。在selayer中用fc层得到num_classes个输出来计算SE-loss。在stage3阶段的另外一个SE-loss的计算是先将特征图通过一个3×3的卷积层使得通道数由1024变为256，再通过一个1×1的卷积层使得通道数与类别数一致，最后再上采样与原始图像大小一致。</p>
<p><strong>code</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncNet</span><span class="params">(BaseNet)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, nclass, backbone, aux=True, se_loss=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                 norm_layer=nn.BatchNorm2d, **kwargs)</span>:</span></span><br><span class="line">        super(EncNet, self).__init__(nclass, backbone, aux, se_loss, norm_layer=norm_layer)</span><br><span class="line">        self.head = EncHead(self.nclass, in_channels=<span class="number">2048</span>, se_loss=se_loss,</span><br><span class="line">                            norm_layer=norm_layer, up_kwargs=self._up_kwargs)</span><br><span class="line">        <span class="keyword">if</span> aux:</span><br><span class="line">            self.auxlayer = FCNHead(<span class="number">1024</span>, nclass, norm_layer=norm_layer)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        imsize = x.size()[<span class="number">2</span>:]</span><br><span class="line">        <span class="comment">#features = self.base_forward(x)</span></span><br><span class="line">        _, _, c3, c4 = self.base_forward(x)</span><br><span class="line"></span><br><span class="line">        x = list(self.head(c4))</span><br><span class="line">        x[<span class="number">0</span>] = upsample(x[<span class="number">0</span>], imsize, **self._up_kwargs)</span><br><span class="line">        <span class="keyword">if</span> self.aux:</span><br><span class="line">            auxout = self.auxlayer(c3)</span><br><span class="line">            auxout = upsample(auxout, imsize, **self._up_kwargs)</span><br><span class="line">            x.append(auxout)</span><br><span class="line">        <span class="keyword">return</span> tuple(x)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncModule</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_channels, nclass, ncodes=<span class="number">32</span>, se_loss=True, norm_layer=None)</span>:</span></span><br><span class="line">        super(EncModule, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> isinstance(norm_layer, encoding.nn.BatchNorm2d):</span><br><span class="line">            norm_layer = encoding.nn.BatchNorm1d</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm1d</span><br><span class="line">        self.se_loss = se_loss</span><br><span class="line">        self.encoding = nn.Sequential(</span><br><span class="line">            encoding.nn.Encoding(D=in_channels, K=ncodes),</span><br><span class="line">            norm_layer(ncodes),</span><br><span class="line">            nn.ReLU(inplace=<span class="keyword">True</span>),</span><br><span class="line">            encoding.nn.Sum(dim=<span class="number">1</span>))</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(in_channels, in_channels),</span><br><span class="line">            nn.Sigmoid())</span><br><span class="line">        <span class="keyword">if</span> self.se_loss:</span><br><span class="line">            self.selayer = nn.Linear(in_channels, nclass)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        en = self.encoding(x)</span><br><span class="line">        b, c, _, _ = x.size()</span><br><span class="line">        gamma = self.fc(en)</span><br><span class="line">        y = gamma.view(b, c, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># residual ?</span></span><br><span class="line">        outputs = [x + x * y]</span><br><span class="line">        <span class="keyword">if</span> self.se_loss:</span><br><span class="line">            outputs.append(self.selayer(en))</span><br><span class="line">        <span class="keyword">return</span> tuple(outputs)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">EncHead</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, out_channels, in_channels, se_loss=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                 norm_layer=None, up_kwargs=None)</span>:</span></span><br><span class="line">        super(EncHead, self).__init__()</span><br><span class="line">        self.conv5 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, <span class="number">512</span>, <span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="keyword">False</span>),</span><br><span class="line">            norm_layer(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(<span class="keyword">True</span>))</span><br><span class="line">        self.encmodule = EncModule(<span class="number">512</span>, out_channels, ncodes=<span class="number">32</span>,</span><br><span class="line">            se_loss=se_loss, norm_layer=norm_layer)</span><br><span class="line">        self.dropout = nn.Dropout2d(<span class="number">0.1</span>, <span class="keyword">False</span>)</span><br><span class="line">        self.conv6 = nn.Conv2d(<span class="number">512</span>, out_channels, <span class="number">1</span>)</span><br><span class="line">        self.se_loss = se_loss</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv5(x)</span><br><span class="line">        outs = list(self.encmodule(x))</span><br><span class="line">        outs[<span class="number">0</span>] = self.conv6(self.dropout(outs[<span class="number">0</span>]))</span><br><span class="line">        <span class="keyword">return</span> tuple(outs)</span><br></pre></td></tr></table></figure></p>
<p><strong>打印出来网络结构如下</strong><br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">(head): EncHead(</span><br><span class="line">    (conv5): Sequential(</span><br><span class="line">      (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), <span class="attribute">bias</span>=<span class="literal">False</span>)</span><br><span class="line">      (1): BatchNorm2d(512, <span class="attribute">eps</span>=1e-05, <span class="attribute">momentum</span>=0.1, <span class="attribute">affine</span>=<span class="literal">True</span>, <span class="attribute">track_running_stats</span>=<span class="literal">True</span>)</span><br><span class="line">      (2): ReLU(inplace)</span><br><span class="line">    )</span><br><span class="line">    (encmodule): EncModule(</span><br><span class="line">      (encoding): Sequential(</span><br><span class="line">        (0): Encoding(N x <span class="attribute">512</span>=&gt;32x512)</span><br><span class="line">        (1): BatchNorm1d(32, <span class="attribute">eps</span>=1e-05, <span class="attribute">momentum</span>=0.1, <span class="attribute">affine</span>=<span class="literal">True</span>, <span class="attribute">track_running_stats</span>=<span class="literal">True</span>)</span><br><span class="line">        (2): ReLU(inplace)</span><br><span class="line">        (3): Sum()</span><br><span class="line">      )</span><br><span class="line">      (fc): Sequential(</span><br><span class="line">        (0): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=512, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">        (1): Sigmoid()</span><br><span class="line">      )</span><br><span class="line">      (selayer): Linear(<span class="attribute">in_features</span>=512, <span class="attribute">out_features</span>=59, <span class="attribute">bias</span>=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">    (dropout): Dropout2d(<span class="attribute">p</span>=0.1)</span><br><span class="line">    (conv6): Conv2d(512, 59, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">(auxlayer): FCNHead(</span><br><span class="line">    (conv5): Sequential(</span><br><span class="line">      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">      (1): BatchNorm2d(256, <span class="attribute">eps</span>=1e-05, <span class="attribute">momentum</span>=0.1, <span class="attribute">affine</span>=<span class="literal">True</span>, <span class="attribute">track_running_stats</span>=<span class="literal">True</span>)</span><br><span class="line">      (2): ReLU()</span><br><span class="line">      (3): Dropout2d(<span class="attribute">p</span>=0.1)</span><br><span class="line">      (4): Conv2d(256, 59, kernel_size=(1, 1), stride=(1, 1))</span><br><span class="line">    )</span><br></pre></td></tr></table></figure></p>
<h1 id="3-Experimental-Results"><a href="#3-Experimental-Results" class="headerlink" title="3. Experimental Results"></a>3. Experimental Results</h1><h2 id="3-1-Implementation-Details"><a href="#3-1-Implementation-Details" class="headerlink" title="3.1 Implementation Details"></a>3.1 Implementation Details</h2><p>ADE20K数据集初始学习率0.01另外两个数据集0.001。<br>momentum 为 0.9<br>weight decay 为 0.0001<br>50 epochs on PASCAL Context and PASCAL VOC 2012, and 120 epochs on ADE20K<br>数据增强：</p>
<ul>
<li>randomly shufﬂe the training samples and discard the last mini-batch</li>
<li>randomly ﬂip</li>
<li>scale the image between 0.5 to 2</li>
<li>randomly rotate the image between -10 to 10 degree</li>
<li>crop the image into ﬁx size using zero padding if needed</li>
</ul>
<p>训练时为了增大batchsize，使用了Synchronized Cross-GPU Batch Normalization，使用了mini-batch size为16，Encoding Layer中的codeword设为32，ground truth通过unique操作来找到在ground truth中出现的类别。最终损失函数为per-pixel segmentation loss和SE-loss的加权求和。</p>
<h2 id="3-2-Results-on-PASCAL-Context"><a href="#3-2-Results-on-PASCAL-Context" class="headerlink" title="3.2 Results on PASCAL-Context"></a>3.2 Results on PASCAL-Context</h2><h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><p><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/03.png" alt=""><br>测试了SE-loss的不同权重$\alpha=\lbrace{0.0,0.1,0.2,0.4,0.8}\rbrace$，发现0.2的效果最好。<br>测试了Encoding Layer中codeword K的取值，最后使用K=32。<br><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/04.png" alt=""><br>更深的基础网络的精度提供更好的精度，用ResNet101最为基础网络，mIoU提升2.5%。<br><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/05.png" alt=""><br>EncNet比之前的state-of-the-art方法更好，并且没有使用COCO预训练或使用更深的ResNet152。<br><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/06.png" alt=""></p>
<h2 id="3-3-Results-on-PASCAL-VOC-2012"><a href="#3-3-Results-on-PASCAL-VOC-2012" class="headerlink" title="3.3 Results on PASCAL VOC 2012"></a>3.3 Results on PASCAL VOC 2012</h2><p><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/07.png" alt=""></p>
<h2 id="3-4-Results-on-ADE20K"><a href="#3-4-Results-on-ADE20K" class="headerlink" title="3.4 Results on ADE20K"></a>3.4 Results on ADE20K</h2><p><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/08.png" alt=""><br><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/09.png" alt=""><br><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/10.png" alt=""></p>
<h2 id="3-4-Image-Classiﬁcation-Results-on-CIFAR-10"><a href="#3-4-Image-Classiﬁcation-Results-on-CIFAR-10" class="headerlink" title="3.4 Image Classiﬁcation Results on CIFAR-10"></a>3.4 Image Classiﬁcation Results on CIFAR-10</h2><p><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/11.png" alt=""><br><img src="/2018/06/11/Context-Encoding-for-Semantic-Segmentation/12.png" alt=""></p>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Semantic-Segmentation/" rel="tag"># Semantic Segmentation</a>
          
            <a href="/tags/Channel-Attention-mechanism/" rel="tag"># Channel Attention mechanism</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/10/ESPNet-Efficient-Spatial-Pyramid-of-Dilated-Convolutions-for-Semantic-Segmentation/" rel="next" title="论文阅读 - ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation">
                <i class="fa fa-chevron-left"></i> 论文阅读 - ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic Segmentation
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/06/12/遥感数据集/" rel="prev" title="遥感数据集">
                遥感数据集 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Bin Zhang</p>
              <p class="site-description motion-element" itemprop="description">I am currently a Master candidate in Wuhan University majoring Photogrammetry and remote sensing</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">26</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">22</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/zhangbin0917" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:bin.zhang@whu.edu.cn" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Introduction"><span class="nav-text">1. Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Context-Encoding-Module"><span class="nav-text">2. Context Encoding Module</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Context-Encoding"><span class="nav-text">Context Encoding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Featuremap-Attention"><span class="nav-text">Featuremap Attention</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Semantic-Encoding-Loss"><span class="nav-text">Semantic Encoding Loss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-Context-Encoding-Network-EncNet"><span class="nav-text">2.1 Context Encoding Network (EncNet)</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Experimental-Results"><span class="nav-text">3. Experimental Results</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-Implementation-Details"><span class="nav-text">3.1 Implementation Details</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-Results-on-PASCAL-Context"><span class="nav-text">3.2 Results on PASCAL-Context</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Ablation-Study"><span class="nav-text">Ablation Study</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-Results-on-PASCAL-VOC-2012"><span class="nav-text">3.3 Results on PASCAL VOC 2012</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-Results-on-ADE20K"><span class="nav-text">3.4 Results on ADE20K</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-Image-Classiﬁcation-Results-on-CIFAR-10"><span class="nav-text">3.4 Image Classiﬁcation Results on CIFAR-10</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Bin Zhang</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="Symbols count total">154k</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="Reading time total">2:20</span>
  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Gemini</a> v6.4.1</div>




        








        
      </div>
    </footer>

    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  



  
  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three-waves.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.4.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.4.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.4.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.4.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.4.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.4.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.1"></script>



  



  










  





  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  

</body>
</html>
